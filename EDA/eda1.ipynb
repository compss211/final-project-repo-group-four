{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55353ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song Title</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>Yeah   I've been tryna call I've been on my ow...</td>\n",
       "      <td>yeah tryna long maybe love maybe withdrawal tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Circles</td>\n",
       "      <td>Oh, oh, oh Oh,  oh, oh Oh,  oh, oh, oh, oh   W...</td>\n",
       "      <td>oh oh oh oh oh oh oh oh oh oh oh turn til upsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>Roddy Ricch</td>\n",
       "      <td>The Box</td>\n",
       "      <td>Pullin' out the coupe at the lot Told 'em fuck...</td>\n",
       "      <td>Pullin coupe lot tell fuck fuck SWAT Bustin be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>Don't Start Now</td>\n",
       "      <td>If you don't wanna see me   Did a full one-eig...</td>\n",
       "      <td>wanna eighty crazy thinking way heartbreak cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>Adore You</td>\n",
       "      <td>Walk in your rainbow paradise (Paradise) Straw...</td>\n",
       "      <td>walk rainbow paradise Paradise Strawberry lips...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Artist       Song Title  \\\n",
       "5913    The Weeknd  Blinding Lights   \n",
       "5914   Post Malone          Circles   \n",
       "5915   Roddy Ricch          The Box   \n",
       "5916      Dua Lipa  Don't Start Now   \n",
       "5917  Harry Styles        Adore You   \n",
       "\n",
       "                                                 Lyrics  \\\n",
       "5913  Yeah   I've been tryna call I've been on my ow...   \n",
       "5914  Oh, oh, oh Oh,  oh, oh Oh,  oh, oh, oh, oh   W...   \n",
       "5915  Pullin' out the coupe at the lot Told 'em fuck...   \n",
       "5916  If you don't wanna see me   Did a full one-eig...   \n",
       "5917  Walk in your rainbow paradise (Paradise) Straw...   \n",
       "\n",
       "                                                 Corpus  \n",
       "5913  yeah tryna long maybe love maybe withdrawal tu...  \n",
       "5914  oh oh oh oh oh oh oh oh oh oh oh turn til upsi...  \n",
       "5915  Pullin coupe lot tell fuck fuck SWAT Bustin be...  \n",
       "5916  wanna eighty crazy thinking way heartbreak cha...  \n",
       "5917  walk rainbow paradise Paradise Strawberry lips...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reducing to necessary columns and year 2020 \n",
    "df = pd.read_csv('../data/all_songs_data_processed.csv')\n",
    "data20 = df[df['Year'] == 2020]\n",
    "data20 = data20[['Artist', 'Song Title', 'Lyrics', 'Corpus']]\n",
    "data20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d06906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Obtaining dependency information for bertopic from https://files.pythonhosted.org/packages/98/05/2d6b305391efff89c2b4cf19cf847f971ca163eb5c149d0d2ffac0a9c7ed/bertopic-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting sentence-transformers\n",
      "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/48/21/4670d03ab8587b0ab6f7d5fa02a95c3dd6b1f39d0e40e508870201f3d76c/sentence_transformers-5.1.1-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting hdbscan>=0.8.29 (from bertopic)\n",
      "  Obtaining dependency information for hdbscan>=0.8.29 from https://files.pythonhosted.org/packages/26/6b/88b8c8023c0c0b27589ad83c82084a1b751917a3e09bdf7fcacf7e6bd523/hdbscan-0.8.40-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading hdbscan-0.8.40-cp311-cp311-macosx_10_9_universal2.whl.metadata (15 kB)\n",
      "Collecting umap-learn>=0.5.0 (from bertopic)\n",
      "  Obtaining dependency information for umap-learn>=0.5.0 from https://files.pythonhosted.org/packages/6b/b1/c24deeda9baf1fd491aaad941ed89e0fed6c583a117fd7b79e0a33a1e6c0/umap_learn-0.5.9.post2-py3-none-any.whl.metadata\n",
      "  Downloading umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from bertopic) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from bertopic) (2.0.3)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from bertopic) (5.9.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from bertopic) (1.3.0)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from bertopic) (4.65.0)\n",
      "Requirement already satisfied: llvmlite>0.36.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from bertopic) (0.40.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.41.0 from https://files.pythonhosted.org/packages/e5/2b/4d2708ac1ff5cd708b6548f4c5812d0ae40d1c28591c4c1c762b6dbdef2d/transformers-4.57.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for torch>=1.11.0 from https://files.pythonhosted.org/packages/3f/14/e105b8ef6d324e789c1589e95cb0ab63f3e07c2216d68b1178b7c21b7d2a/torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: scipy in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.20.0 from https://files.pythonhosted.org/packages/31/a0/651f93d154cb72323358bf2bbae3e642bdb5d2f1bfc874d096f7cb159fa0/huggingface_hub-0.35.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
      "Requirement already satisfied: filelock in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/47/71/70db47e4f6ce3e5c37a607355f80da8860a33226be640226ac52cb05ef2e/fsspec-2025.9.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Obtaining dependency information for hf-xet<2.0.0,>=1.1.3 from https://files.pythonhosted.org/packages/f7/a2/343e6d05de96908366bdc0081f2d8607d61200be2ac802769c4284cc65bd/hf_xet-1.1.10-cp37-abi3-macosx_10_12_x86_64.whl.metadata\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-macosx_10_12_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.5->bertopic) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from plotly>=4.7.0->bertopic) (8.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0->bertopic) (2.2.0)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for typing_extensions>=4.5.0 from https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: sympy in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Obtaining dependency information for tokenizers<=0.23.0,>=0.22.0 from https://files.pythonhosted.org/packages/bf/33/f4b2d94ada7ab297328fc671fed209368ddb82f965ec2224eb1892674c3a/tokenizers-0.22.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.3 from https://files.pythonhosted.org/packages/4d/b1/3f5fd73c039fc87dba3ff8b5d528bfc5a32b597fea8e7a6a4800343a17c7/safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting scikit-learn>=1.0 (from bertopic)\n",
      "  Obtaining dependency information for scikit-learn>=1.0 from https://files.pythonhosted.org/packages/43/83/564e141eef908a5863a54da8ca342a137f45a0bfb71d1d79704c9894c9d1/scikit_learn-1.7.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numba>=0.51.2 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from umap-learn>=0.5.0->bertopic) (0.57.0)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
      "  Obtaining dependency information for pynndescent>=0.5 from https://files.pythonhosted.org/packages/d2/53/d23a97e0a2c690d40b165d1062e2c4ccc796be458a1ce59f6ba030434663/pynndescent-0.5.13-py3-none-any.whl.metadata\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.0->bertopic)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jazminegamboa/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.6/486.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hdbscan-0.8.40-cp311-cp311-macosx_10_9_universal2.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-macosx_10_9_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-macosx_10_12_x86_64.whl (454 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-macosx_10_12_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing_extensions, threadpoolctl, safetensors, hf-xet, fsspec, torch, scikit-learn, huggingface-hub, tokenizers, pynndescent, hdbscan, umap-learn, transformers, sentence-transformers, bertopic\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.3.2\n",
      "    Uninstalling safetensors-0.3.2:\n",
      "      Successfully uninstalled safetensors-0.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.1\n",
      "    Uninstalling transformers-4.32.1:\n",
      "      Successfully uninstalled transformers-4.32.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bertopic-0.17.3 fsspec-2025.9.0 hdbscan-0.8.40 hf-xet-1.1.10 huggingface-hub-0.35.3 pynndescent-0.5.13 safetensors-0.6.2 scikit-learn-1.7.2 sentence-transformers-5.1.1 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.2.2 transformers-4.57.0 typing_extensions-4.15.0 umap-learn-0.5.9.post2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bertopic sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data20\n",
    "lyrics = df[\"Lyrics\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cad8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398b978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-string lyrics (e.g., nan values)\n",
    "clean_lyrics = [lyric if isinstance(lyric, str) else \"\" for lyric in lyrics]\n",
    "\n",
    "topic_model = BERTopic(language=\"english\")\n",
    "topics, probs = topic_model.fit_transform(clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f479f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>-1_the_featuring_la_me</td>\n",
       "      <td>[the, featuring, la, me, que, to, of, de, no, ...</td>\n",
       "      <td>[Beyoncé  COLORS Black Pumas  ROCKSTAR DaBaby ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0_you_the_to_me</td>\n",
       "      <td>[you, the, to, me, my, and, love, it, dont, that]</td>\n",
       "      <td>[There stands the glass That will ease all my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1_the_you_it_im</td>\n",
       "      <td>[the, you, it, im, in, and, yeah, to, my, that]</td>\n",
       "      <td>[Ugh, you're a monster  [Verse 1: Eminem] I ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                    Name  \\\n",
       "0     -1     15  -1_the_featuring_la_me   \n",
       "1      0     51         0_you_the_to_me   \n",
       "2      1     34         1_the_you_it_im   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [the, featuring, la, me, que, to, of, de, no, ...   \n",
       "1  [you, the, to, me, my, and, love, it, dont, that]   \n",
       "2    [the, you, it, im, in, and, yeah, to, my, that]   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Beyoncé  COLORS Black Pumas  ROCKSTAR DaBaby ...  \n",
       "1  [There stands the glass That will ease all my ...  \n",
       "2  [Ugh, you're a monster  [Verse 1: Eminem] I ca...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baf8096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 0.11878008742688179),\n",
       " ('the', 0.07099698147244424),\n",
       " ('to', 0.061392393863085926),\n",
       " ('me', 0.05876725550909064),\n",
       " ('my', 0.05522073973419982),\n",
       " ('and', 0.0513015323466842),\n",
       " ('love', 0.04819094692700823),\n",
       " ('it', 0.04757841375944383),\n",
       " ('dont', 0.045781082354474076),\n",
       " ('that', 0.040173285300268854)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfced52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
